# -*- coding: utf-8 -*-
"""jailbreak.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FG9n4Sbs_-tjULpoWrW9Qhl4re5N1q5g
"""

# =============================================================================
# MAIN SCRIPT
# =============================================================================

import os
import json
import pickle
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split

from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback,
    set_seed
)
from torch.utils.data import Dataset

os.environ["WANDB_MODE"] = "offline"
set_seed(42)

class Config:
    test_mode = False
    output_dir = './jailbreak_model'
    model_name = "distilbert-base-uncased"
    max_length = 512
    batch_size = 8
    num_epochs = 3
    learning_rate = 2e-5

config = Config()

class JailbreakDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = int(self.labels[idx])

        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

def load_data():
    try:
        dataset = load_dataset("jackhhao/jailbreak-classification", "balanced")
    except:
        try:
            dataset = load_dataset("jackhhao/jailbreak-classification")
        except Exception as e:
            print(f"Error loading dataset: {e}")
            return None, None, None

    print(f"Dataset splits: {list(dataset.keys())}")

    all_data = []
    for split_name in dataset.keys():
        split_data = dataset[split_name]
        df = pd.DataFrame(split_data)
        all_data.append(df)
        print(f"{split_name}: {len(df)} samples")

    # combine all splits
    df = pd.concat(all_data, ignore_index=True)
    print(f"Total samples: {len(df)}")
    print(f"Columns: {df.columns.tolist()}")

    if 'prompt' in df.columns and 'type' in df.columns:
        text_col = 'prompt'
        label_col = 'type'
        print(f"Using: text='{text_col}', label='{label_col}'")
    else:
        print(f"Expected 'prompt' and 'type' columns not found!")
        print(f"Available columns: {df.columns.tolist()}")
        print(f"First sample: {df.iloc[0].to_dict()}")
        return None, None, None

    print(f"Unique label values: {sorted(df[label_col].unique())}")

    texts = df[text_col].astype(str).tolist()
    labels = df[label_col].tolist()
    unique_labels = sorted(set(labels))
    print(f"Unique labels: {unique_labels}")

    if len(unique_labels) != 2:
        print(f"Error: Expected 2 unique labels, found {len(unique_labels)}")
        return None, None, None

    # create label mapping
    label_map = {}

    # check if labels are strings and map appropriately
    if isinstance(unique_labels[0], str):
        for label in unique_labels:
            label_lower = label.lower()
            if any(word in label_lower for word in ['jailbreak', 'malicious', 'unsafe', 'harmful', 'bad']):
                label_map[label] = 1
            elif any(word in label_lower for word in ['safe', 'benign', 'good', 'normal']):
                label_map[label] = 0

        if len(label_map) != 2:
            label_map = {unique_labels[0]: 0, unique_labels[1]: 1}

        labels = [label_map[l] for l in labels]
        print(f"Label mapping: {label_map}")

    elif set(unique_labels) == {0, 1}:
        print("Labels already in binary format")
    else:
        label_map = {unique_labels[0]: 0, unique_labels[1]: 1}
        labels = [label_map[l] for l in labels]
        print(f"Mapped labels: {label_map}")

    print(f"Final label distribution: {pd.Series(labels).value_counts().to_dict()}")

    # filter short texts
    filtered_data = [(t, l) for t, l in zip(texts, labels) if len(str(t).strip()) >= 10]
    texts, labels = zip(*filtered_data) if filtered_data else ([], [])

    print(f"After filtering: {len(texts)} samples")

    if len(texts) == 0:
        print("No valid samples found")
        return None, None, None

    texts = np.array(texts)
    labels = np.array(labels)

    # create golden test set
    n_test = max(1, int(0.1 * len(texts)))

    indices = np.arange(len(texts))
    np.random.seed(42)
    np.random.shuffle(indices)
    test_idx = indices[:n_test]
    train_val_idx = indices[n_test:]

    # golden test set
    test_texts = texts[test_idx]
    test_labels = labels[test_idx]

    remaining_texts = texts[train_val_idx]
    remaining_labels = labels[train_val_idx]

    # for test mode use only 5 examples
    if config.test_mode:
        remaining_texts = remaining_texts[:5]
        remaining_labels = remaining_labels[:5]
        print("TEST MODE: Using only 5 samples")

    train_texts, val_texts, train_labels, val_labels = train_test_split(
        remaining_texts, remaining_labels, test_size=0.2, random_state=42,
        stratify=remaining_labels if len(set(remaining_labels)) > 1 else None
    )

    print(f"Train: {len(train_texts)}, Val: {len(val_texts)}, Test: {len(test_texts)}")

    test_df = pd.DataFrame({'text': test_texts, 'label': test_labels})
    test_df.to_csv('golden_test_jailbreak.csv', index=False)

    return (train_texts, train_labels), (val_texts, val_labels), (test_texts, test_labels)

def setup_model():
    tokenizer = AutoTokenizer.from_pretrained(config.model_name)
    model = AutoModelForSequenceClassification.from_pretrained(
        config.model_name,
        num_labels=2
    )

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    print(f"Device: {device}")

    return model, tokenizer

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)

    accuracy = accuracy_score(labels, predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, predictions, average='binary', zero_division=0
    )

    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

def train_model(model, tokenizer, train_data, val_data):
    train_texts, train_labels = train_data
    val_texts, val_labels = val_data

    train_dataset = JailbreakDataset(train_texts, train_labels, tokenizer, config.max_length)
    val_dataset = JailbreakDataset(val_texts, val_labels, tokenizer, config.max_length)

    training_args = TrainingArguments(
        output_dir=f'{config.output_dir}/checkpoints',
        num_train_epochs=config.num_epochs if not config.test_mode else 1,
        per_device_train_batch_size=config.batch_size,
        per_device_eval_batch_size=16,
        warmup_steps=100 if not config.test_mode else 5,
        weight_decay=0.01,
        logging_steps=10 if not config.test_mode else 1,
        eval_strategy="steps",
        eval_steps=50 if not config.test_mode else 1,
        save_steps=100 if not config.test_mode else 1,
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model="f1",
        greater_is_better=True,
        report_to=None,
        seed=42
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
    )

    print("Starting training...")
    start_time = datetime.now()

    trainer.train()

    training_time = datetime.now() - start_time
    print(f"Training completed in: {training_time}")

    os.makedirs(config.output_dir, exist_ok=True)
    trainer.save_model(config.output_dir)
    tokenizer.save_pretrained(config.output_dir)

    return trainer, training_time

def evaluate_model(trainer, tokenizer, val_data, test_data):
    val_texts, val_labels = val_data
    test_texts, test_labels = test_data

    val_dataset = JailbreakDataset(val_texts, val_labels, tokenizer, config.max_length)
    test_dataset = JailbreakDataset(test_texts, test_labels, tokenizer, config.max_length)

    val_pred = trainer.predict(val_dataset)
    test_pred = trainer.predict(test_dataset)

    val_pred_labels = np.argmax(val_pred.predictions, axis=1)
    test_pred_labels = np.argmax(test_pred.predictions, axis=1)

    def calc_metrics(y_true, y_pred, name):
        acc = accuracy_score(y_true, y_pred)
        prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)

        print(f"\n{name} Results:")
        print(f"Accuracy:  {acc:.4f}")
        print(f"Precision: {prec:.4f}")
        print(f"Recall:    {rec:.4f}")
        print(f"F1-Score:  {f1:.4f}")

        return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}

    val_results = calc_metrics(val_labels, val_pred_labels, "VALIDATION")
    test_results = calc_metrics(test_labels, test_pred_labels, "GOLDEN TEST")

    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    cm_val = confusion_matrix(val_labels, val_pred_labels)
    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',
               xticklabels=['Safe', 'Jailbreak'],
               yticklabels=['Safe', 'Jailbreak'], ax=axes[0])
    axes[0].set_title('Validation - Confusion Matrix')

    cm_test = confusion_matrix(test_labels, test_pred_labels)
    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues',
               xticklabels=['Safe', 'Jailbreak'],
               yticklabels=['Safe', 'Jailbreak'], ax=axes[1])
    axes[1].set_title('Golden Test - Confusion Matrix')

    plt.tight_layout()
    plt.savefig(f'{config.output_dir}/confusion_matrices.png', dpi=300, bbox_inches='tight')
    plt.show()

    results = {'validation': val_results, 'golden_test': test_results}
    with open(f'{config.output_dir}/results.json', 'w') as f:
        json.dump(results, f, indent=2)

    return results

def main():
    try:
        print(f"Mode: {'TEST' if config.test_mode else 'FULL'}")

        train_data, val_data, test_data = load_data()
        if train_data is None:
            return

        model, tokenizer = setup_model()
        trainer, training_time = train_model(model, tokenizer, train_data, val_data)
        results = evaluate_model(trainer, tokenizer, val_data, test_data)

        print(f"Training time: {training_time}")
        print(f"Validation F1: {results['validation']['f1']:.4f}")
        print(f"Golden Test F1: {results['golden_test']['f1']:.4f}")
        print(f"Model saved to: {config.output_dir}")

    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

# ================================================================================
# DOWNLOAD SCRIPT
# ================================================================================

import os
import zipfile
from google.colab import files

def check_jailbreak_files():
    main_dir = './jailbreak_model'
    print("Files in jailbreak_model directory:")
    if os.path.exists(main_dir):
        for f in os.listdir(main_dir):
            if os.path.isfile(os.path.join(main_dir, f)):
                size = os.path.getsize(os.path.join(main_dir, f))
                print(f"  {f} ({size:,} bytes)")

def download_jailbreak_complete():
    zip_filename = 'jailbreak_model_complete.zip'

    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
        main_dir = './jailbreak_model'
        if os.path.exists(main_dir):
            for f in os.listdir(main_dir):
                if os.path.isfile(os.path.join(main_dir, f)):
                    file_path = os.path.join(main_dir, f)

                    # Put model files in model/ folder, results in results/
                    if f.endswith(('.safetensors', '.json', '.txt')) and 'results' not in f:
                        zipf.write(file_path, f'model/{f}')
                    else:
                        zipf.write(file_path, f'results/{f}')

                    size = os.path.getsize(file_path)
                    print(f"Added: {f} ({size/1024/1024:.1f}MB)")

        if os.path.exists('golden_test_jailbreak.csv'):
            zipf.write('golden_test_jailbreak.csv', 'data/golden_test_jailbreak.csv')
            print("Added: golden_test_jailbreak.csv")

    print(f"Package created: {zip_filename}")
    files.download(zip_filename)

check_jailbreak_files()
download_jailbreak_complete()
